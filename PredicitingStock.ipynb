{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nv0KwAkxnJYH"
   },
   "source": [
    "**references**\n",
    "\n",
    "https://www.statworx.com/at/blog/how-to-build-a-dashboard-in-python-plotly-dash-step-by-step-tutorial/\n",
    "https://github.com/STATWORX/blog/blob/master/DashApp/app_basic.py\n",
    "\n",
    "https://pierpaolo28.github.io/blog/blog21/\n",
    "https://github.com/pierpaolo28/Data-Visualization/tree/master/Dash\n",
    "\n",
    "https://dash.plotly.com/deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxow6sFBcszo"
   },
   "source": [
    "# https://plotly.com/python/filled-area-plots/\n",
    "\n",
    "between area: same color, but no different colors: color btw PMA and MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16390,
     "status": "ok",
     "timestamp": 1612139959635,
     "user": {
      "displayName": "Xiaolong Liu",
      "photoUrl": "",
      "userId": "08359873075849330876"
     },
     "user_tz": 300
    },
    "id": "tw5bX-rqdfVy",
    "outputId": "51687c59-f340-48c8-fe64-b89faab7ee78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dash in c:\\users\\13237\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: plotly>=5.0.0 in c:\\users\\13237\\anaconda3\\lib\\site-packages (from dash) (5.4.0)\n",
      "Requirement already satisfied: dash-html-components==2.0.0 in c:\\users\\13237\\anaconda3\\lib\\site-packages (from dash) (2.0.0)\n",
      "Requirement already satisfied: dash-core-components==2.0.0 in c:\\users\\13237\\anaconda3\\lib\\site-packages (from dash) (2.0.0)\n",
      "Requirement already satisfied: flask-compress in c:\\users\\13237\\anaconda3\\lib\\site-packages (from dash) (1.10.1)\n",
      "Requirement already satisfied: Flask>=1.0.4 in c:\\users\\13237\\anaconda3\\lib\\site-packages (from dash) (1.1.2)\n",
      "Requirement already satisfied: dash-table==5.0.0 in c:\\users\\13237\\anaconda3\\lib\\site-packages (from dash) (5.0.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in c:\\users\\13237\\anaconda3\\lib\\site-packages (from Flask>=1.0.4->dash) (2.11.3)\n",
      "Requirement already satisfied: click>=5.1 in c:\\users\\13237\\anaconda3\\lib\\site-packages (from Flask>=1.0.4->dash) (7.1.2)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in c:\\users\\13237\\anaconda3\\lib\\site-packages (from Flask>=1.0.4->dash) (1.0.1)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\users\\13237\\anaconda3\\lib\\site-packages (from Flask>=1.0.4->dash) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\13237\\anaconda3\\lib\\site-packages (from Jinja2>=2.10.1->Flask>=1.0.4->dash) (1.1.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\13237\\anaconda3\\lib\\site-packages (from plotly>=5.0.0->dash) (8.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\13237\\anaconda3\\lib\\site-packages (from plotly>=5.0.0->dash) (1.15.0)\n",
      "Requirement already satisfied: brotli in c:\\users\\13237\\anaconda3\\lib\\site-packages (from flask-compress->dash) (1.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7199,
     "status": "ok",
     "timestamp": 1612140017496,
     "user": {
      "displayName": "Xiaolong Liu",
      "photoUrl": "",
      "userId": "08359873075849330876"
     },
     "user_tz": 300
    },
    "id": "clN7sZtuCFRq",
    "outputId": "9112c8af-526f-45ae-b491-801707d2659a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\13237\\anaconda3\\lib\\site-packages (0.1.67)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\13237\\anaconda3\\lib\\site-packages (from yfinance) (1.2.4)\n",
      "Requirement already satisfied: lxml>=4.5.1 in c:\\users\\13237\\anaconda3\\lib\\site-packages (from yfinance) (4.6.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\13237\\anaconda3\\lib\\site-packages (from yfinance) (0.0.10)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\13237\\anaconda3\\lib\\site-packages (from yfinance) (1.20.1)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\13237\\anaconda3\\lib\\site-packages (from yfinance) (2.25.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\13237\\anaconda3\\lib\\site-packages (from pandas>=0.24->yfinance) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\13237\\anaconda3\\lib\\site-packages (from pandas>=0.24->yfinance) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\13237\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\13237\\anaconda3\\lib\\site-packages (from requests>=2.20->yfinance) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\13237\\anaconda3\\lib\\site-packages (from requests>=2.20->yfinance) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\13237\\anaconda3\\lib\\site-packages (from requests>=2.20->yfinance) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\13237\\anaconda3\\lib\\site-packages (from requests>=2.20->yfinance) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance --upgrade --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5749,
     "status": "ok",
     "timestamp": 1612140017497,
     "user": {
      "displayName": "Xiaolong Liu",
      "photoUrl": "",
      "userId": "08359873075849330876"
     },
     "user_tz": 300
    },
    "id": "3UUvVMyCayZa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-7e2eed0b809f>:5: UserWarning: \n",
      "The dash_html_components package is deprecated. Please replace\n",
      "`import dash_html_components as html` with `from dash import html`\n",
      "  import dash_html_components as html\n",
      "<ipython-input-3-7e2eed0b809f>:6: UserWarning: \n",
      "The dash_core_components package is deprecated. Please replace\n",
      "`import dash_core_components as dcc` with `from dash import dcc`\n",
      "  import dash_core_components as dcc\n"
     ]
    }
   ],
   "source": [
    "#!pip install dash\n",
    "\n",
    "import dash ## local \n",
    "#from jupyter_dash import JupyterDash # colab\n",
    "import dash_html_components as html\n",
    "import dash_core_components as dcc\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1612140021950,
     "user": {
      "displayName": "Xiaolong Liu",
      "photoUrl": "",
      "userId": "08359873075849330876"
     },
     "user_tz": 300
    },
    "id": "TOw8STlCcszu"
   },
   "outputs": [],
   "source": [
    "stock_list = [\"FB\", \"AAPL\", \"AMZN\", \"NFLX\", \"GOOG\", \"MSFT\", \"XLK\", \"QQQ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1981,
     "status": "ok",
     "timestamp": 1612140023604,
     "user": {
      "displayName": "Xiaolong Liu",
      "photoUrl": "",
      "userId": "08359873075849330876"
     },
     "user_tz": 300
    },
    "id": "-dGHGL17cszx",
    "outputId": "d6063947-7b44-4e7d-9141-690cbaf822ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# to get predict data\n",
    "stock_dic = dict()\n",
    "\n",
    "for stock in stock_list:\n",
    "    df = yf.download(stock, start=\"2019-7-25\").drop(columns='Adj Close')\n",
    "    df.dropna(inplace=True)\n",
    "    stock_dic[stock] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2hfyEWovcsz0"
   },
   "source": [
    "# predict1, predict2, predict3, MA, PMA, UpDown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2077,
     "status": "ok",
     "timestamp": 1612140025733,
     "user": {
      "displayName": "Xiaolong Liu",
      "photoUrl": "",
      "userId": "08359873075849330876"
     },
     "user_tz": 300
    },
    "id": "fe1ZP11Mcsz1",
    "outputId": "276889dc-570a-4d7e-a095-6d2d58b0b210"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# get normalizer\n",
    "df1_dic={}\n",
    "for stock in stock_list:\n",
    "    data = yf.download(stock, start=\"2012-05-18\", end=\"2020-07-23\")\n",
    "    # data, meta_data = ts.get_daily(symbol=stock,outputsize = 'full')\n",
    "    # data.sort_values(by='date', inplace=True) \n",
    "    data = data.drop(columns='Adj Close')\n",
    "    df1_dic[stock] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1164,
     "status": "ok",
     "timestamp": 1612140025734,
     "user": {
      "displayName": "Xiaolong Liu",
      "photoUrl": "",
      "userId": "08359873075849330876"
     },
     "user_tz": 300
    },
    "id": "0eRrPFW-csz3"
   },
   "outputs": [],
   "source": [
    "history_points = 50\n",
    "def getXtest(data, data_nor):\n",
    "    data = data.to_numpy()\n",
    "    data2 = data_nor.to_numpy()\n",
    "    \n",
    "    data_normaliser = preprocessing.MinMaxScaler()\n",
    "    data_normaliser = data_normaliser.fit(data)\n",
    "    data_normalised = data_normaliser.transform(data)\n",
    "    \n",
    "    Xtest = np.array([data_normalised[i : i + history_points].copy() for i in range(len(data) - history_points+1)])\n",
    "#     next_day_open_values = np.array([data2[:,0][i + history_points].copy() for i in range(len(data2) - history_points)])\n",
    "    next_day_open_values = np.array([data[:,0][i + history_points].copy() for i in range(len(data) - history_points)])\n",
    "    next_day_open_values = np.expand_dims(next_day_open_values, -1)\n",
    "  \n",
    "    next_day_close_values = np.array([data[:,3][i + history_points].copy() for i in range(len(data) - history_points)])\n",
    "    next_day_close_values = np.expand_dims(next_day_close_values, -1)\n",
    "    \n",
    "    y_normaliser_open = preprocessing.MinMaxScaler()\n",
    "    y_normaliser_open.fit(next_day_open_values)\n",
    "    \n",
    "    y_normaliser_close = preprocessing.MinMaxScaler()\n",
    "    y_normaliser_close.fit(next_day_close_values)\n",
    "\n",
    "    return Xtest, y_normaliser_open, y_normaliser_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 909,
     "status": "ok",
     "timestamp": 1612140025735,
     "user": {
      "displayName": "Xiaolong Liu",
      "photoUrl": "",
      "userId": "08359873075849330876"
     },
     "user_tz": 300
    },
    "id": "GQFKr1Rncsz6"
   },
   "outputs": [],
   "source": [
    "# 1 day prediction: close, open (for candle stick)\n",
    "def getResult1(stock):\n",
    "    data = stock_dic[stock]\n",
    "    data_nor = df1_dic[stock]\n",
    "    \n",
    "    model_open = tf.keras.models.load_model('{}_model_open'.format(stock))\n",
    "    model_close = tf.keras.models.load_model('{}_model'.format(stock))\n",
    "    \n",
    "    Xtest, y_normaliser_open, y_normaliser_close = getXtest(data, data_nor)\n",
    "\n",
    "    open_pred = model_open.predict(Xtest)\n",
    "    open_pred = np.reshape(open_pred, (open_pred.shape[0], 1))\n",
    "    open_pred = y_normaliser_open.inverse_transform(open_pred)\n",
    "    \n",
    "    close_pred = model_close.predict(Xtest)\n",
    "    close_pred =np.reshape(close_pred, (close_pred.shape[0], 1))\n",
    "    close_pred = y_normaliser_close.inverse_transform(close_pred)\n",
    "    \n",
    "    # return open_pred, close_pred\n",
    "    return np.reshape(open_pred, open_pred.shape[0]), np.reshape(close_pred, close_pred.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1612140026199,
     "user": {
      "displayName": "Xiaolong Liu",
      "photoUrl": "",
      "userId": "08359873075849330876"
     },
     "user_tz": 300
    },
    "id": "xwJNbyBFcsz9"
   },
   "outputs": [],
   "source": [
    "def getResult_days(stock, prediction_days):\n",
    "\n",
    "    data = stock_dic[stock]\n",
    "    data_nor = df1_dic[stock]\n",
    "    \n",
    "    data1 = data.to_numpy()\n",
    "    \n",
    "    data_normaliser = preprocessing.MinMaxScaler()\n",
    "    data_normalised = data_normaliser.fit_transform(data1)\n",
    "\n",
    "    model = tf.keras.models.load_model('{}_model_'.format(stock)+str(prediction_days)+'days')\n",
    "    \n",
    "    Xtest, y_normaliser_open, y_normaliser = getXtest(data, data_nor)\n",
    "    \n",
    "    y_test_predicted = model.predict(Xtest)\n",
    "    y_test_predicted = np.reshape(y_test_predicted, (y_test_predicted.shape[0], prediction_days))\n",
    "    y_test_predicted = y_normaliser.inverse_transform(y_test_predicted)\n",
    "    \n",
    "    y_test_prediction = []\n",
    "    for i in y_test_predicted[:-1]:\n",
    "        y_test_prediction.append(i[0])\n",
    "    \n",
    "    y_pred = y_test_prediction + list(y_test_predicted[-1])\n",
    "    \n",
    "    if prediction_days != 2:\n",
    "        return y_pred\n",
    "    \n",
    "    else: # add PMA, MA if prediction_days = 2\n",
    "        one_day_data = []\n",
    "        day4_data = []\n",
    "        ma = []\n",
    "\n",
    "        period = len(data)-history_points\n",
    "        for i in range(period-1,-1,-1):\n",
    "            ma.append(sum(data['Close'].iloc[-i-7:-i-1])/6)\n",
    "            one_day_data.append(data_normalised[-i-51:-i-1])\n",
    "            day4_data.append(sum(data['Close'].iloc[-i-5:-i-1]))\n",
    "        one_day_data = np.array(one_day_data)\n",
    "\n",
    "        one_day_predict = model.predict(one_day_data)\n",
    "        one_day_predict =np.reshape(one_day_predict, (one_day_predict.shape[0], prediction_days))\n",
    "        one_day_predicted = y_normaliser.inverse_transform(one_day_predict)\n",
    "\n",
    "        day6_sum = []\n",
    "        for i in range(period):\n",
    "            s = day4_data[i] + one_day_predicted[i][0] + one_day_predicted[i][1]\n",
    "            day6_sum.append(s/6)\n",
    "\n",
    "        PMA = [day6_sum[i] for i in range(period)]\n",
    "        MA = [ma[i] for i in range(period)]\n",
    "\n",
    "        UpDown = []\n",
    "        for i in range(len(PMA)):\n",
    "            if PMA[i] >= MA[i]:\n",
    "                UpDown.append(1)\n",
    "            else:\n",
    "                UpDown.append(0)\n",
    "\n",
    "        return y_pred, PMA, MA, UpDown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "executionInfo": {
     "elapsed": 472,
     "status": "error",
     "timestamp": 1612140027203,
     "user": {
      "displayName": "Xiaolong Liu",
      "photoUrl": "",
      "userId": "08359873075849330876"
     },
     "user_tz": 300
    },
    "id": "KO5-mWd7cs0A",
    "outputId": "1bfe07c9-4d1b-4d4c-caeb-ee5d18e8a8f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "df_dic = dict()\n",
    "\n",
    "for stock in stock_list:\n",
    "    result_frame = stock_dic[stock].copy().loc[stock_dic[stock].index[history_points]:]\n",
    "    idx = pd.date_range(result_frame.index[-1], periods=4, freq='B')[1:]\n",
    "    open_pred, close_pred = getResult1(stock)\n",
    "\n",
    "    pred2, PMA, MA, UpDown = getResult_days(stock, 2)\n",
    "    pred3 = getResult_days(stock, 3)\n",
    "#     pred30 = getResult_days(stock, 30)\n",
    "\n",
    "\n",
    "    for i, date in enumerate(idx):\n",
    "    # Open High Low Close Volume\n",
    "#         if i ==0:\n",
    "#             openpp = open_pred[-1]\n",
    "#             closepp = close_pred[-1]\n",
    "#             result_frame.loc[pd.to_datetime(date)] = [open_pred[-1], max(openpp,closepp), min(openpp,closepp), close_pred[-1], None]\n",
    "#         else:\n",
    "        result_frame.loc[pd.to_datetime(date)] = [None, None, None, None, None]\n",
    "    \n",
    "    \n",
    "    result_frame['Open_Pred'] = list(open_pred) + [None for i in range(len(result_frame)-len(open_pred))]\n",
    "    result_frame['Close_Pred1'] = list(close_pred) + [None for i in range(len(result_frame)-len(close_pred))]\n",
    "    result_frame['Close_Pred2'] = list(pred2) + [None for i in range(len(result_frame)-len(pred2))]\n",
    "    result_frame['Close_Pred3'] = list(pred3) + [None for i in range(len(result_frame)-len(pred3))]\n",
    "#     result_frame['Close_Pred30'] = pred30\n",
    "    result_frame['PMA'] = PMA + [None for i in range(len(result_frame)-len(PMA))]\n",
    "    result_frame['MA'] = MA + [None for i in range(len(result_frame)-len(MA))]\n",
    "    result_frame['UpDown'] = UpDown + [None for i in range(len(result_frame)-len(UpDown))]\n",
    "\n",
    "    \n",
    "    close = stock_dic[stock].Close[history_points-1:]\n",
    "\n",
    "    colors = list()\n",
    "    for i in range(1, len(close)):\n",
    "        if close[i-1] <= close[i]:\n",
    "            colors.append('green')\n",
    "        else:\n",
    "            colors.append('red')        \n",
    "    \n",
    "    result_frame['colors'] = colors + ['red' for i in range(len(result_frame)-len(colors))]    \n",
    "    \n",
    "    df_dic[stock] = result_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "kkEqizc-cs0C"
   },
   "outputs": [],
   "source": [
    "PIndex_MA_1 = {}\n",
    "PIndex_MA_2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0lhp4YWbcs0E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "# Pindex\n",
    "# 3 days prediction: close prediction (for candle stick)\n",
    "# 1 day close prediction \n",
    "for key in stock_list:\n",
    "    data = stock_dic[key]\n",
    "    data_nor = df1_dic[key]\n",
    "    \n",
    "    model_close = tf.keras.models.load_model('{}_model'.format(key))\n",
    "    \n",
    "    Xtest, y_normaliser_open, y_normaliser_close = getXtest(data, data_nor)\n",
    "\n",
    "    \n",
    "    close_pred = model_close.predict(Xtest)\n",
    "    close_pred = np.array([i[0] for i in close_pred])\n",
    "    close_pred = y_normaliser_close.inverse_transform(close_pred)\n",
    "    \n",
    "    period = len(data)-history_points\n",
    "    \n",
    "    one_year = data.iloc[-period:]\n",
    "    data1 = data.to_numpy()\n",
    "    data_normaliser = preprocessing.MinMaxScaler()\n",
    "    data_normalised = data_normaliser.fit_transform(data1)\n",
    "    \n",
    "    one_day_data = []\n",
    "    day1_data = []\n",
    "    ma = []\n",
    "    for i in range(period-1,-1,-1):\n",
    "        ma.append(sum(data['Close'].iloc[-i-4:-i-1])/3)\n",
    "        one_day_data.append(data_normalised[-i-51:-i-1])\n",
    "        day1_data.append(data['Close'].iloc[-i-1])\n",
    "    one_day_data = np.array(one_day_data)\n",
    "    one_day_predict = model_close.predict(one_day_data)\n",
    "    one_day_predict = np.array([i[0] for i in one_day_predict])\n",
    "\n",
    "    one_day_predicted = y_normaliser_close.inverse_transform(one_day_predict)\n",
    "    \n",
    "    day3_sum1 = []\n",
    "    day3_sum2 = []\n",
    "    for i in range(period-1):\n",
    "        s = day1_data[i] +one_day_predicted[i][0] + one_day_predicted[i+1][0]\n",
    "\n",
    "        day3_sum1.append(s/3)\n",
    " \n",
    "    for i in range(period-2):\n",
    "        s2 = one_day_predicted[i][0] + one_day_predicted[i+1][0]+ one_day_predicted[i+2][0]\n",
    "\n",
    "        day3_sum2.append(s2/3)\n",
    "    moving_average1 = pd.DataFrame(index = one_year.index[:-1],columns=['PIndex','MA'],data=[[day3_sum1[i],ma[i]] for i in range(period-1)])\n",
    "    list1 = []\n",
    "    for i in moving_average1.index:\n",
    "        if moving_average1['PIndex'][i] >= moving_average1['MA'][i]:\n",
    "            list1.append('green')\n",
    "        else:\n",
    "            list1.append('red')\n",
    "    moving_average1['Trend'] = list1\n",
    "    PIndex_MA_1[key] = moving_average1\n",
    "    \n",
    "#   Pindex 2\n",
    "    moving_average2 = pd.DataFrame(index = one_year.index[:-2],columns=['PIndex','MA'],data=[[day3_sum2[i],ma[i]] for i in range(period-2)])\n",
    "    list2 = []\n",
    "    for i in moving_average2.index:\n",
    "        if moving_average2['PIndex'][i] >= moving_average2['MA'][i]:\n",
    "            list2.append('green')\n",
    "        else:\n",
    "            list2.append('red')\n",
    "    moving_average2['Trend'] = list2\n",
    "    \n",
    "    PIndex_MA_2[key] = moving_average2\n",
    "    \n",
    "# #     model_open = tf.keras.models.load_model('{}_model_open'.format(stock))\n",
    "#     model_close = tf.keras.models.load_model('{}_model'.format(key))\n",
    "    \n",
    "#     Xtest, y_normaliser_open, y_normaliser_close = getXtest(data, data_nor)\n",
    "\n",
    "# # #     open_pred = model_open.predict(Xtest)\n",
    "# # #     open_pred = y_normaliser_open.inverse_transform(open_pred)\n",
    "    \n",
    "#     close_pred = model_close.predict(Xtest)\n",
    "#     close_pred = np.array([i[0] for i in close_pred]) #np.reshape(close_pred, (close_pred.shape[0], 3))\n",
    "#     close_pred = y_normaliser_close.inverse_transform(close_pred)\n",
    "    \n",
    "#     period = len(data)-history_points\n",
    "    \n",
    "#     one_year = data.iloc[-period:] # one_month = data.iloc[history_points:]\n",
    "#     data1 = data.to_numpy()\n",
    "#     data_normaliser = preprocessing.MinMaxScaler()\n",
    "#     data_normalised = data_normaliser.fit_transform(data1)\n",
    "    \n",
    "#     one_day_data = []\n",
    "#     day1_data = []\n",
    "#     ma = []\n",
    "#     for i in range(period-1,-1,-1):\n",
    "#         ma.append(sum(data['Close'].iloc[-i-4:-i-1])/3)\n",
    "#         one_day_data.append(data_normalised[-i-51:-i-1])\n",
    "#         day1_data.append(data['Close'].iloc[-i-1])\n",
    "#     # for i in range(31,-1,-1):\n",
    "#     #     one_day_data.append(data_normalised[-i-51:-i-1])\n",
    "#     one_day_data = np.array(one_day_data)\n",
    "#     one_day_predict = model_close.predict(one_day_data)\n",
    "#     one_day_predict = np.array([i[0] for i in one_day_predict])\n",
    "#     #one_day_predict = np.reshape(one_day_predict, (one_day_predict.shape[0], 3))\n",
    "    \n",
    "#     one_day_predicted = y_normaliser_close.inverse_transform(one_day_predict)\n",
    "    \n",
    "#     day3_sum1 = []\n",
    "#     day3_sum2 = []\n",
    "#     for i in range(period-1):\n",
    "#         s = day1_data[i] +one_day_predicted[i][0] + one_day_predicted[i+1][0]\n",
    "\n",
    "#         day3_sum1.append(s/3)\n",
    " \n",
    "#     for i in range(period-2):\n",
    "#         s2 = one_day_predicted[i][0] + one_day_predicted[i+1][0]+ one_day_predicted[i+2][0]\n",
    "\n",
    "#         day3_sum2.append(s2/3)\n",
    "#     moving_average1 = pd.DataFrame(index = one_year.index[:-1],columns=['PIndex','MA'],data=[[day3_sum1[i],ma[i]] for i in range(period-1)])\n",
    "#     list1 = []\n",
    "#     for i in moving_average1.index:\n",
    "#         if moving_average1['PIndex'][i] >= moving_average1['MA'][i]:\n",
    "#             list1.append('green')\n",
    "#         else:\n",
    "#             list1.append('red')\n",
    "#     moving_average1['Trend'] = list1\n",
    "#     PIndex_MA_1[key] = moving_average1\n",
    "    \n",
    "# #   Pindex 2\n",
    "#     moving_average2 = pd.DataFrame(index = one_year.index[:-2],columns=['PIndex','MA'],data=[[day3_sum2[i],ma[i]] for i in range(period-2)])\n",
    "#     list2 = []\n",
    "#     for i in moving_average2.index:\n",
    "#         if moving_average2['PIndex'][i] >= moving_average2['MA'][i]:\n",
    "#             list2.append('green')\n",
    "#         else:\n",
    "#             list2.append('red')\n",
    "#     moving_average2['Trend'] = list2\n",
    " \n",
    "\n",
    "#     PIndex_MA_2[key] = moving_average2\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "fQSBWVoZcs0H"
   },
   "outputs": [],
   "source": [
    "df_dic2 = dict()\n",
    "\n",
    "for stock in stock_list:\n",
    "    result_frame = df_dic[stock]\n",
    "    \n",
    "    list1 = list(PIndex_MA_1[stock].Trend)\n",
    "    \n",
    "    constant1 = [1 for i in range(len(list1))]+ [None, None, None, None]\n",
    "    PIndex_color1 = list1 + ['red', 'red', 'red', 'red']\n",
    "\n",
    "    \n",
    "    result_frame['constant1'] = constant1\n",
    "    result_frame['PIndex_color1'] = PIndex_color1\n",
    "    \n",
    "    # pindex2\n",
    "    list2 = list(PIndex_MA_2[stock].Trend)\n",
    "        \n",
    "    constant2 = [1 for i in range(len(list2))]+ [None, None, None, None, None]\n",
    "    PIndex_color2 = list2 + ['red', 'red', 'red', 'red', 'red']\n",
    "\n",
    "    \n",
    "    result_frame['constant2'] = constant2\n",
    "    result_frame['PIndex_color2'] = PIndex_color2\n",
    "    \n",
    "\n",
    "    df_dic2[stock] = result_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "s9bmnqipcs0K",
    "outputId": "b0f449c4-401e-421e-af03-0d16a6054911"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-17 00:00:00\n",
      "2021-12-20 00:00:00\n",
      "2021-12-22 00:00:00\n"
     ]
    }
   ],
   "source": [
    "today = df_dic2['FB'].index[-4]\n",
    "# next_date30 = df_dic['FB'].index[-1]\n",
    "next_days = pd.date_range(today, periods=4, freq='B')\n",
    "next_date = next_days[1]\n",
    "next_date3 = next_days[-1]\n",
    "# daysBTW = int(str(next_date3-today)[:2])+1\n",
    "\n",
    "print(today)\n",
    "print(next_date)\n",
    "print(next_date3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "qqAPXiKpcs0M"
   },
   "outputs": [],
   "source": [
    "candle_dic = dict()\n",
    "for stock in stock_list:\n",
    "    Open = list()\n",
    "    Close = list()\n",
    "    High = list()\n",
    "    Low = list()\n",
    "    result_frame = df_dic[stock].copy()\n",
    "    for date in result_frame.index:\n",
    "        if date != next_date:\n",
    "            Open.append(result_frame.loc[date].Open)\n",
    "            Close.append(result_frame.loc[date].Close)\n",
    "            High.append(result_frame.loc[date].High)\n",
    "            Low.append(result_frame.loc[date].Low)\n",
    "        else:\n",
    "            Open.append(result_frame.loc[next_date].Open_Pred)\n",
    "            Close.append(result_frame.loc[next_date].Close_Pred1)\n",
    "            High.append(max(result_frame.loc[next_date].Open_Pred,result_frame.loc[next_date].Close_Pred1))\n",
    "            Low.append(min(result_frame.loc[next_date].Open_Pred,result_frame.loc[next_date].Close_Pred1))\n",
    "    df = pd.DataFrame(data={'Open': Open, \"High\":High,\"Low\":Low,'Close':Close})\n",
    "    df = df.set_index(result_frame.index)\n",
    "    candle_dic[stock] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "wf9o2vb0cs0P"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "f1 = open(\"test1.pkl\",\"wb\")\n",
    "f2 = open(\"test2.pkl\",\"wb\")\n",
    "pickle.dump(df_dic2,f1)\n",
    "\n",
    "f1.close()\n",
    "pickle.dump(candle_dic,f2)\n",
    "\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgbAI1Hv4k3l"
   },
   "source": [
    "Get result files and then visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "H_BLXrN5cs0R"
   },
   "outputs": [],
   "source": [
    "options_list = [\n",
    "    {'label': 'Apple', 'value': 'AAPL'},\n",
    "    {'label': 'Amazon', 'value': 'AMZN'},\n",
    "    {'label': 'Facebook', 'value': 'FB'},\n",
    "    {'label': 'Google', 'value': 'GOOG'},\n",
    "    {'label': 'Microsoft', 'value': 'MSFT'},\n",
    "    {'label': 'Neflix', 'value': 'NFLX'},\n",
    "    {'label': 'XLK', 'value': 'XLK'}, \n",
    "    {'label': 'QQQ', 'value': 'QQQ'}    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "EqLT_zwVcs0T"
   },
   "outputs": [],
   "source": [
    "date_options_list = [\n",
    "    {'label': '2 Days', 'value': -5},\n",
    "    {'label': '5 Days', 'value': -8},\n",
    "    {'label': '1 Month', 'value': -27},\n",
    "    {'label': '3 Month', 'value': -69},\n",
    "    {'label': '6 Month', 'value': -133},\n",
    "    {'label': 'All', 'value': 'all'}  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "O-NL_Poocs0X"
   },
   "outputs": [],
   "source": [
    "# Initialize the app\n",
    "app = dash.Dash(__name__) ## local\n",
    "#app = JupyterDash(__name__) # colab\n",
    "app.config.suppress_callback_exceptions = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "kL5ZPLbBcs0Z"
   },
   "outputs": [],
   "source": [
    "app.layout = html.Div([\n",
    "# Setting the main title of the Dashboard\n",
    "    html.H1(\"Stock Price Prediction\", style={\"textAlign\": \"center\"}),\n",
    "    \n",
    "    html.Div([\n",
    "        html.H1(\"Please select stock and time period.\", \n",
    "            style={'textAlign': 'center'}),\n",
    "            # Adding the first dropdown menu and the subsequent time-series graph\n",
    "            dcc.Dropdown(id='stock_select',\n",
    "                options=options_list, # multi=True,\n",
    "                value='AAPL',\n",
    "                style={\"display\": \"block\", \"margin-left\": \"auto\", \n",
    "                    \"margin-right\": \"auto\", \"width\": \"60%\"}),\n",
    "        \n",
    "            dcc.Dropdown(id='date_select',\n",
    "                options=date_options_list, # multi=True,\n",
    "                value=-69,\n",
    "                style={\"display\": \"block\", \"margin-left\": \"auto\", \n",
    "                    \"margin-right\": \"auto\", \"width\": \"60%\"}),\n",
    "                dcc.Graph(id='basicGraph'),                \n",
    "#                 dcc.Graph(id='pindexGraph1'),\n",
    "                dcc.Graph(id='pindexGraph2'),\n",
    "                dcc.Graph(id='predictionGraph'),\n",
    "                dcc.Graph(id='volumeGraph'),\n",
    "        \n",
    "            ])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "IS0yE10vcs0c"
   },
   "outputs": [],
   "source": [
    "@app.callback(Output('basicGraph', 'figure'),\n",
    "              [Input('stock_select', 'value'), Input('date_select', 'value')])\n",
    "\n",
    "def update_graph(selected_dropdown, selected_date):\n",
    "\n",
    "    trace1 = []\n",
    "    trace2 = []\n",
    "    trace3 = []\n",
    "    trace4 = []\n",
    "    trace5 = []\n",
    "    trace6 = []\n",
    "    trace7 = []\n",
    "    trace8 = []\n",
    "    \n",
    "    if selected_date == 'all':\n",
    "        result_frame = df_dic2[selected_dropdown].copy()\n",
    "        candle_frame = candle_dic[selected_dropdown].copy()\n",
    "    else:\n",
    "        result_frame = df_dic2[selected_dropdown].copy().iloc[selected_date:]\n",
    "        candle_frame = candle_dic[selected_dropdown].copy().iloc[selected_date:]\n",
    "\n",
    "    trace1.append(\n",
    "      go.Candlestick(x=candle_frame.index, visible='legendonly',\n",
    "                     open=candle_frame.Open,\n",
    "                     high=candle_frame.High,\n",
    "                     low=candle_frame.Low,\n",
    "                     close=candle_frame.Close,\n",
    "                     name=f'Candlestick'))\n",
    "\n",
    "    trace2.append(\n",
    "      go.Scatter(x=result_frame.index,\n",
    "                 y=result_frame.MA,\n",
    "                 mode='lines', opacity=0.8, #fill=\"tonexty\",\n",
    "                 name=f'MA', #,textposition='bottom center',\n",
    "                line = dict(color='chocolate')))\n",
    "    \n",
    "    trace3.append(\n",
    "      go.Scatter(x=result_frame.index,\n",
    "                 y=result_frame.PMA,\n",
    "                 mode='lines', opacity=0.9, #fill='tonexty',\n",
    "                 name=f'PMA',#textposition='bottom center',\n",
    "                 line = dict(color='blue')))\n",
    "    \n",
    "    trace4.append(\n",
    "      go.Scatter(x=result_frame.index,\n",
    "                 y=result_frame.Open, visible='legendonly',\n",
    "                 mode='lines', opacity=0.8, line=dict(color=\"orange\", width=4, dash='dot'),\n",
    "                 name=f'Open')) #,textposition='bottom center'))\n",
    "    \n",
    "    trace5.append(\n",
    "      go.Scatter(x=result_frame.index,\n",
    "                 y=result_frame.Close, visible='legendonly',\n",
    "                 mode='lines', opacity=0.6, line=dict(color=\"teal\", width=4, dash='dash'),\n",
    "                 name=f'Close')) #,textposition='bottom center'))\n",
    "    \n",
    "    trace6.append(\n",
    "      go.Scatter(x=result_frame.index,\n",
    "                 y=result_frame.Close_Pred1, visible='legendonly',\n",
    "                 mode='lines', opacity=0.8, line_color= \"cyan\",\n",
    "                 name=f'Predict 1day')) #,textposition='bottom center'))\n",
    "    trace7.append(\n",
    "      go.Scatter(x=result_frame.index,\n",
    "                 y=result_frame.Close_Pred2, visible='legendonly',\n",
    "                 mode='lines', opacity=0.8, line_color= \"magenta\",\n",
    "                 name=f'Predict 2days')) #,textposition='bottom center'))\n",
    "    \n",
    "    trace8.append(\n",
    "      go.Scatter(x=result_frame.index,\n",
    "                 y=result_frame.Close_Pred3, visible='legendonly',\n",
    "                 mode='lines', opacity=0.8, line_color= \"navy\",\n",
    "                 name=f'Predict 3days')) #,textposition='bottom center'))\n",
    "     \n",
    "    traces = [trace1, trace2, trace3, trace4, trace5, trace6, trace7, trace8]\n",
    " \n",
    "    data = [val for sublist in traces for val in sublist]\n",
    "    figure = {'data': data,\n",
    "              'layout': go.Layout( #colorway=[\"#5E0DAC\", '#800000', '#FFA500', \n",
    "                                    #        '#00FFFF', '#FF00FF','#0000FF'],\n",
    "            hovermode='x unified',\n",
    "            height=500, \n",
    "            margin=dict(\n",
    "#             t=10, # top margin: 30px, you want to leave around 30 pixels to\n",
    "#               # display the modebar above the graph.\n",
    "            b=20, # bottom margin: 10px\n",
    "#             l=40, # left margin: 10px\n",
    "#             r=40, # right margin: 10px\n",
    "            ),\n",
    "            legend=dict(\n",
    "                orientation=\"h\",              \n",
    "                yanchor=\"bottom\",\n",
    "                y=1.02,\n",
    "                xanchor=\"right\",\n",
    "                x=1),\n",
    "             title=f\"{selected_dropdown}\", xaxis={'rangeslider': {'visible': False}, 'type': 'date'},\n",
    "#             yaxis =  {\"title\":\"Price\", \"range\":[min(result_frame.Open)*0.75,max(result_frame.Open*1.1)],\n",
    "#                       'fixedrange': False},               \n",
    "      \n",
    "                  \n",
    "#             yaxis2={\"title\":\"Volume\", \"side\":\"right\", \"overlaying\":\"y\", \n",
    "#                     \"range\":[min(result_frame.Volume),max(result_frame.Volume)*4]},                                                  \n",
    "                  \n",
    "                  \n",
    "             shapes=[\n",
    "                    dict(\n",
    "                        type=\"rect\",\n",
    "                        xref=\"x\",\n",
    "                        yref=\"paper\",\n",
    "                        x0=next_date+pd.DateOffset(-1),\n",
    "                        y0=\"0\",\n",
    "                        x1=result_frame.index[-1],\n",
    "                        y1=\"1\",\n",
    "                        fillcolor=\"lightgray\",\n",
    "                        opacity=0.4,\n",
    "                        line_width=0,\n",
    "                        layer=\"below\"\n",
    "                    ),\n",
    "                    ],  \n",
    "                  \n",
    "# #             xaxis={#\"title\":\"Date\",\n",
    "# # #                    'rangeselector': {'buttons': list([\n",
    "# # #                        {'count': daysBTW, 'label': '1D', 'step': 'day','stepmode': 'backward'},\n",
    "# # #                        {'count': daysBTW+6, 'label': '5D', 'step': 'day', 'stepmode': 'backward'},                       \n",
    "# # #                        {'count': daysBTW+30, 'label': '1M', 'step': 'day', 'stepmode': 'backward'},\n",
    "# # #                        {'count': daysBTW+92, 'label': '3M', 'step': 'day', 'stepmode': 'backward'},\n",
    "# # #                        {'count': daysBTW+183, 'label': '6M', 'step': 'day','stepmode': 'backward'},\n",
    "# # #                        {'step': 'all'}])},                \n",
    "# #                    'rangeslider': {'visible': False}, \n",
    "# #                    'type': 'date'}, \n",
    "                  \n",
    "\n",
    "              )}    \n",
    "    \n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "LvDzEylccs0f"
   },
   "outputs": [],
   "source": [
    "@app.callback(Output('pindexGraph2', 'figure'),\n",
    "              [Input('stock_select', 'value'), Input('date_select', 'value')])\n",
    "\n",
    "def update_graph4(selected_dropdown, selected_date):\n",
    "\n",
    "    trace21 = []\n",
    "    \n",
    "    if selected_date == 'all':\n",
    "        result_frame = df_dic2[selected_dropdown].copy()\n",
    "    else:\n",
    "        result_frame = df_dic2[selected_dropdown].copy().iloc[selected_date:]\n",
    "\n",
    "   \n",
    "    trace21.append(\n",
    "      go.Bar(x=result_frame.index, y=result_frame.constant2,opacity=0.7, \n",
    "                      name=f'Pindex2',marker_color=result_frame.PIndex_color2)) \n",
    "\n",
    "  \n",
    "    traces = [trace21]\n",
    " \n",
    "    data = [val for sublist in traces for val in sublist]\n",
    "    figure = {'data': data, \n",
    "              'layout': go.Layout( #colorway=[\"#5E0DAC\", '#800000', '#FFA500', \n",
    "                                    #        '#00FFFF', '#FF00FF','#0000FF'],\n",
    "            height=10, \n",
    "            margin=dict(\n",
    "            t=0, # top margin: 30px, you want to leave around 30 pixels to\n",
    "              # display the modebar above the graph.\n",
    "            b=0, # bottom margin: 10px\n",
    "#             l=40, # left margin: 10px\n",
    "#             r=40, # right margin: 10px\n",
    "            ),\n",
    "            legend=dict(\n",
    "                orientation=\"h\",              \n",
    "                yanchor=\"bottom\",\n",
    "                y=1.02,\n",
    "                xanchor=\"right\",\n",
    "                x=1),\n",
    "             title=f\"{selected_dropdown} Pindex2\", \n",
    "             xaxis={'rangeslider': {'visible': False}, 'type': 'date'},\n",
    "             yaxis = {'showticklabels': False, 'showgrid': False},   \n",
    "#             yaxis =  {\"title\":\"Price\", \"range\":[min(result_frame[:-30].Open)*0.75,max(result_frame[:-30].Open*1.1)],\n",
    "#                       'fixedrange': False},\n",
    "                \n",
    "                  shapes=[\n",
    "                    dict(\n",
    "                        type=\"rect\",\n",
    "                        xref=\"x\",\n",
    "                        yref=\"paper\",\n",
    "                        x0=next_date+pd.DateOffset(-1),\n",
    "                        y0=\"0\",\n",
    "                        x1=result_frame.index[-1],\n",
    "                        y1=\"1\",\n",
    "                        fillcolor=\"lightgray\",\n",
    "                        opacity=0.4,\n",
    "                        line_width=0,\n",
    "                        layer=\"below\"\n",
    "                    ),\n",
    "                    ],            \n",
    "                  \n",
    "#             yaxis2={\"title\":\"Volume\", \"side\":\"right\", \"overlaying\":\"y\", \n",
    "#                     \"range\":[min(result_frame[:-30].Volume),max(result_frame[:-30].Volume)*4]},\n",
    "              )}    \n",
    "                  \n",
    "   \n",
    "    return figure\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "he_n4A7Fcs0h"
   },
   "outputs": [],
   "source": [
    "@app.callback(Output('predictionGraph', 'figure'),\n",
    "              [Input('stock_select', 'value'), Input('date_select', 'value')])\n",
    "def update_graph3(selected_dropdown, selected_date):\n",
    "\n",
    "    trace6 = []\n",
    "    trace7 = []\n",
    "    trace8 = []\n",
    "    \n",
    "    trace11 = []    \n",
    "    \n",
    "    if selected_date == 'all':\n",
    "        result_frame = df_dic2[selected_dropdown].copy()\n",
    "    else:\n",
    "        result_frame = df_dic2[selected_dropdown].copy().iloc[selected_date:]\n",
    "\n",
    "\n",
    "    trace6.append(\n",
    "      go.Scatter(x=result_frame.index,\n",
    "                 y=result_frame.Close_Pred1, #visible='legendonly',\n",
    "                 mode='lines', opacity=0.8, line_color= \"cyan\",\n",
    "                 name=f'Predict 1day')) #,textposition='bottom center'))\n",
    "    trace7.append(\n",
    "      go.Scatter(x=result_frame.index,\n",
    "                 y=result_frame.Close_Pred2, #visible='legendonly',\n",
    "                 mode='lines', opacity=0.8, line_color= \"magenta\",\n",
    "                 name=f'Predict 2days')) #,textposition='bottom center'))\n",
    "    \n",
    "    trace8.append(\n",
    "      go.Scatter(x=result_frame.index,\n",
    "                 y=result_frame.Close_Pred3, #visible='legendonly',\n",
    "                 mode='lines', opacity=0.8, line_color= \"navy\",\n",
    "                 name=f'Predict 3days')) #,textposition='bottom center'))\n",
    "    \n",
    "    # next day candle: 'Open_Pred', 'Close_Pred1',\n",
    "    Open = list()\n",
    "    Close = list()\n",
    "    High = list()\n",
    "    Low = list()\n",
    "    \n",
    "    hovertext = list()\n",
    "    \n",
    "    for date in result_frame.index:\n",
    "        if date != next_date:\n",
    "            Open.append(None)\n",
    "            Close.append(None)\n",
    "            High.append(None)\n",
    "            Low.append(None)\n",
    "            hovertext.append(None)\n",
    "        else:\n",
    "            Open.append(result_frame.loc[next_date].Open_Pred)\n",
    "            Close.append(result_frame.loc[next_date].Close_Pred1)\n",
    "            High.append(max(result_frame.loc[next_date].Open_Pred,result_frame.loc[next_date].Close_Pred1))\n",
    "            Low.append(min(result_frame.loc[next_date].Open_Pred,result_frame.loc[next_date].Close_Pred1))\n",
    "            hovertext.append('Open: '+str(result_frame.loc[next_date].Open_Pred)+'<br>Close: '+str(result_frame.loc[next_date].Close_Pred1))\n",
    "    \n",
    "    trace11.append(\n",
    "      go.Candlestick(x=result_frame.index, visible='legendonly',\n",
    "                     open=Open,\n",
    "                     high=High,\n",
    "                     low=Low,\n",
    "                     close=Close, opacity=0.7, \n",
    "                     #increasing_line_color= 'green', decreasing_line_color= 'red',\n",
    "                     name=f'next candle',  \n",
    "                     text = hovertext,\n",
    "                     hoverinfo='text'))  \n",
    "  \n",
    "    traces = [trace6, trace7, trace8, trace11]\n",
    " \n",
    "    data = [val for sublist in traces for val in sublist]\n",
    "    figure = {'data': data, \n",
    "              'layout': go.Layout( #colorway=[\"#5E0DAC\", '#800000', '#FFA500', \n",
    "                                    #        '#00FFFF', '#FF00FF','#0000FF'],\n",
    "            hovermode='x unified',\n",
    "            height=300, \n",
    "                  \n",
    "            margin=dict(\n",
    "            t=50, # top margin: 30px, you want to leave around 30 pixels to\n",
    "#               # display the modebar above the graph.\n",
    "            b=0, # bottom margin: 10px\n",
    "#             l=40, # left margin: 10px\n",
    "#             r=40, # right margin: 10px\n",
    "            ),\n",
    "            legend=dict(\n",
    "                orientation=\"h\",              \n",
    "                yanchor=\"bottom\",\n",
    "                y=1.02,\n",
    "                xanchor=\"right\",\n",
    "                x=1),\n",
    "             #title=f\"{selected_dropdown}\", \n",
    "             xaxis={'rangeslider': {'visible': False}, 'type': 'date'},\n",
    "                  \n",
    "#             yaxis =  {\"title\":\"Price\", \"range\":[min(result_frame[:-30].Open)*0.75,max(result_frame[:-30].Open*1.1)],\n",
    "#                       'fixedrange': False},\n",
    "                \n",
    "                  shapes=[\n",
    "                    dict(\n",
    "                        type=\"rect\",\n",
    "                        xref=\"x\",\n",
    "                        yref=\"paper\",\n",
    "                        x0=next_date+pd.DateOffset(-1),\n",
    "                        y0=\"0\",\n",
    "                        x1=result_frame.index[-1],\n",
    "                        y1=\"1\",\n",
    "                        fillcolor=\"lightgray\",\n",
    "                        opacity=0.4,\n",
    "                        line_width=0,\n",
    "                        layer=\"below\"\n",
    "                    ),\n",
    "                    ],            \n",
    "                  \n",
    "#             yaxis2={\"title\":\"Volume\", \"side\":\"right\", \"overlaying\":\"y\", \n",
    "#                     \"range\":[min(result_frame[:-30].Volume),max(result_frame[:-30].Volume)*4]},\n",
    "              )}    \n",
    "                  \n",
    "   \n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "BiZtosu4cs0j"
   },
   "outputs": [],
   "source": [
    "@app.callback(Output('volumeGraph', 'figure'),\n",
    "              [Input('stock_select', 'value'), Input('date_select', 'value')])\n",
    "\n",
    "def update_graph2(selected_dropdown, selected_date):\n",
    "\n",
    "    trace10 = []\n",
    "\n",
    "    \n",
    "    if selected_date == 'all':\n",
    "        result_frame = df_dic2[selected_dropdown].copy()\n",
    "    else:\n",
    "        result_frame = df_dic2[selected_dropdown].copy().iloc[selected_date:]\n",
    "\n",
    "\n",
    "   \n",
    "    trace10.append(\n",
    "      go.Bar(x=result_frame.index, y=result_frame.Volume,opacity=0.7, \n",
    "                      name=f'Volume',marker_color=result_frame.colors)) \n",
    "\n",
    "  \n",
    "    traces = [trace10]\n",
    " \n",
    "    data = [val for sublist in traces for val in sublist]\n",
    "    figure = {'data': data,\n",
    "              'layout': go.Layout( #colorway=[\"#5E0DAC\", '#800000', '#FFA500', \n",
    "                                    #        '#00FFFF', '#FF00FF','#0000FF'],\n",
    "            height=300, \n",
    "            margin=dict(\n",
    "            t=50, # top margin: 30px, you want to leave around 30 pixels to\n",
    "#               # display the modebar above the graph.\n",
    "#             b=0, # bottom margin: 10px\n",
    "#             l=40, # left margin: 10px\n",
    "#             r=40, # right margin: 10px\n",
    "            ),\n",
    "            legend=dict(\n",
    "                orientation=\"h\",              \n",
    "                yanchor=\"bottom\",\n",
    "                y=1.02,\n",
    "                xanchor=\"right\",\n",
    "                x=1),\n",
    "              \n",
    "             xaxis={'rangeslider': {'visible': False}, 'type': 'date', \"title\": f\"{selected_dropdown} Volume\"},\n",
    "                  \n",
    "#             yaxis =  {\"title\":\"Price\", \"range\":[min(result_frame[:-30].Open)*0.75,max(result_frame[:-30].Open*1.1)],\n",
    "#                       'fixedrange': False},\n",
    "                \n",
    "                  shapes=[\n",
    "                    dict(\n",
    "                        type=\"rect\",\n",
    "                        xref=\"x\",\n",
    "                        yref=\"paper\",\n",
    "                        x0=next_date+pd.DateOffset(-1),\n",
    "                        y0=\"0\",\n",
    "                        x1=result_frame.index[-1],\n",
    "                        y1=\"1\",\n",
    "                        fillcolor=\"lightgray\",\n",
    "                        opacity=0.4,\n",
    "                        line_width=0,\n",
    "                        layer=\"below\"\n",
    "                    ),\n",
    "                    ],            \n",
    "                  \n",
    "#             yaxis2={\"title\":\"Volume\", \"side\":\"right\", \"overlaying\":\"y\", \n",
    "#                     \"range\":[min(result_frame[:-30].Volume),max(result_frame[:-30].Volume)*4]},\n",
    "              )}    \n",
    "                  \n",
    "   \n",
    "    return figure\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4718,
     "status": "ok",
     "timestamp": 1597033673948,
     "user": {
      "displayName": "Myunghee Lee",
      "photoUrl": "",
      "userId": "09294017020174528311"
     },
     "user_tz": 420
    },
    "id": "u6MpW5akb-xz",
    "outputId": "9ce57877-696a-4301-f32a-db23a4f62bf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:38] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:38] \"\u001b[37mGET /_dash-component-suites/dash/deps/polyfill@7.v2_0_0m1639889173.12.1.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:38] \"\u001b[37mGET /assets/style.css?m=1597001100.0 HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:38] \"\u001b[37mGET /_dash-component-suites/dash/deps/react@16.v2_0_0m1639889173.14.0.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:38] \"\u001b[37mGET /_dash-component-suites/dash/deps/react-dom@16.v2_0_0m1639889173.14.0.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:38] \"\u001b[37mGET /_dash-component-suites/dash/deps/prop-types@15.v2_0_0m1639889173.7.2.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:38] \"\u001b[37mGET /_dash-component-suites/dash/dash-renderer/build/dash_renderer.v2_0_0m1639889172.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:38] \"\u001b[37mGET /_dash-component-suites/dash/dcc/dash_core_components.v2_0_0m1639889173.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:38] \"\u001b[37mGET /_dash-component-suites/dash/dcc/dash_core_components-shared.v2_0_0m1639889173.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:38] \"\u001b[37mGET /_dash-component-suites/dash/html/dash_html_components.v2_0_0m1639889173.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:38] \"\u001b[37mGET /_dash-component-suites/dash/dash_table/bundle.v5_0_0m1639889172.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:38] \"\u001b[37mGET /_dash-layout HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:38] \"\u001b[37mGET /_dash-dependencies HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:38] \"\u001b[37mGET /_favicon.ico?v=2.0.0 HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:38] \"\u001b[37mGET /_dash-component-suites/dash/dcc/async-dropdown.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:38] \"\u001b[37mGET /_dash-component-suites/dash/dcc/async-graph.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:38] \"\u001b[37mGET /_dash-component-suites/dash/dcc/async-plotlyjs.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:46] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:46] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:46] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:46] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:52] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:52] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:52] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:58:52] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:59:02] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:59:02] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:59:02] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:59:02] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:59:22] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:59:22] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:59:22] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [18/Dec/2021 20:59:22] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Run the app\n",
    "\n",
    "#app.run_server(mode='inline')  # colab\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(port = 8050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X4tUbXQ0cs0q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "visualization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
